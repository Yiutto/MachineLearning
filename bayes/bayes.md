## 朴素贝叶斯


### 优点
在数据较少的情况下仍然有效，可以处理多分类问题
### 缺点
对于输入数据的准备方式较为敏感
### 适用数据范围
标称型
### 一般流程
- (1) 收集数据：可以使用任何方法。
- (2) 准备数据：需要数值型或者布尔型数据。
- (3) 分析数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好。
- (4) 训练算法：计算不同的独立特征的条件概率。
- (5) 测试算法：计算错误率。
- (6) 使用算法：一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴
素贝叶斯分类器，不一定非要是文本。

朴素：

1.特征相互独立（一个特征或者单词出现的可能性与它和其他单词相邻没有关系）

2.每个特征同等重要

### 实现方式
朴素贝叶斯分类器通常有两种实现方式：一种基于贝努利模型实现，一种基于多项式模型实现。这里采用前一种
实现方式。该实现方式中并不考虑词在文档中出现的次数，只考虑出不出现，因此在这个意义上相当于假设词是
等权重的。

### 部分代码
```angular2html
# sys.path.extend(['F:\\workspace\\python3\\MachineLearning\\bayes'])
import os
# 打印当前工作目录
print(os.getcwd()) 
# 改变当前目录
os.chdir('F:/workspace/python3/MachineLearning/bayes') 
import bayes
listPosts, listClasses = bayes.loadDataSet()
myVocabList = bayes.createVocabList(listPosts)
bayes.setOfWords2Vec(myVocabList, listPosts[0])

```
#### 伪代码
```angularjs
计算每个类别中的文档数目
对每篇训练文档：
    对每个类别：
        如果词条出现在文档中→ 增加该词条的计数值
        增加所有词条的计数值
    对每个类别：
        对每个词条：
            将该词条的数目除以总词条数目得到条件概率
    返回每个类别的条件概率
```

```angular2html
import importlib
importlib.reload(bayes)
listPosts, listClasses = bayes.loadDataSet()
myVocabList = bayes.createVocabList(listPosts)
# 定义文档矩阵
trainMat = []
for postinDoc in listPosts:
    trainMat.append(bayes.setOfWords2Vec(myVocabList, postinDoc))
p0V, p1V, pAb = bayes.trainNB0(trainMat, listClasses)
```
利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概
率，即计算p(w0|1)p(w1|1)p(w2|1)。如果其中一个概率值为0，那么最后的乘积也为0。为降低
这种影响，可以将所有词的出现数初始化为1，并将分母初始化为2。

另一个遇到的问题是下溢出，这是由于太多很小的数相乘造成的。当计算乘积
p(w0|ci)p(w1|ci)p(w2|ci)...p(wN|ci)时，由于大部分因子都非常小，所以程序会下溢出或者
得到不正确的答案。（读者可以用Python尝试相乘许多很小的数，最后四舍五入后会得到0。）一
种解决办法是对乘积取自然对数。在代数中有ln(a*b) = ln(a)+ln(b)，于是通过求对数可以
避免下溢出或者浮点数舍入导致的错误。同时，采用自然对数进行处理不会有任何损失。

#### 文档词袋模型
目前为止，我们将每个词的出现与否作为一个特征，这可以被描述为词集模型（set-of-words 
model）。如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表
达的某种信息，这种方法被称为词袋模型（bag-of-words model）。在词袋中，每个单词可以出现
多次，而在词集中，每个词只能出现一次。

```angularjs
示例：使用朴素贝叶斯对电子邮件进行分类
(1) 收集数据：提供文本文件。
(2) 准备数据：将文本文件解析成词条向量。
(3) 分析数据：检查词条确保解析的正确性。
(4) 训练算法：使用我们之前建立的trainNB0()函数。
(5) 测试算法：使用classifyNB()，并且构建一个新的测试函数来计算文档集的错误率。
(6) 使用算法：构建一个完整的程序对一组文档进行分类，将错分的文档输出到屏幕上。
```
### 小结
本章使用的算法为ID3，无法直接处理数值型数据（可以通过量化的方法将数值型数据转化为
标称数字），但是如果存在太多的特征划分，ID3算法仍然会有其他问题。

为了减少过度匹配问题，我们可以裁剪决策树，去掉一些不
必要的叶子节点。如果叶子节点只能增加少许信息，则可以删除该节点，将它并入到其他叶子节
点中，CART算法

